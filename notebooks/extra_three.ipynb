{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Дополнительное задание 3**\n",
    "\n",
    "В этом задании вам предстоит обучить две модели для предсказания рейтинга отзывов об отелях.\n",
    "\n",
    "1. Загрузите датасет отзывов - [Trip Advisor Hotel Reviews](https://www.kaggle.com/datasets/andrewmvd/trip-advisor-hotel-reviews)\n",
    "2. Подготовьте данные к обучению - **1 балл**\n",
    "    - Разделите датасет на обучающую, валидационную и тестовую выборки со стратификацией в пропорции 60/20/20.\n",
    "    - Создайте `Dataset` и `DataLoader` для обучающей, валидационной и тестовой выборок. Выберите оптимальный, на ваш взгляд, `batch_size`.\n",
    "3. Реализуйте и обучите сверточную сеть (сеть с использованием слоев Conv1d) для решения задачи - **1 балл**\n",
    "4. Реализуйте и обучите рекуррентную сеть (сеть с использованием LSTM-слоя) для решения задачи - **1 балл**\n",
    "5. Сравните между собой метрики и динамику обучения обеих моделей - **1 балл**\n",
    "\n",
    "**Общее**\n",
    "\n",
    "Обеспечена воспроизводимость решения: зафиксированы random_state, ноутбук воспроизводится от начала до конца без ошибок - **1 балл**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Основные библиотеки\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch и связанные библиотеки\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Метрики\n",
    "from torchmetrics.classification import Accuracy, F1Score\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "# HuggingFace Tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_state(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "set_random_state(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay, went seahawk game aweso...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  nice hotel expensive parking got good deal sta...       4\n",
       "1  ok nothing special charge diamond member hilto...       2\n",
       "2  nice rooms not 4* experience hotel monaco seat...       3\n",
       "3  unique, great stay, wonderful time hotel monac...       5\n",
       "4  great stay great stay, went seahawk game aweso...       5"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузка датасета из csv\n",
    "file_path = \"../data/tripadvisor_hotel_reviews.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 12294, Validation size: 4098, Test size: 4099\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных на X (тексты) и y (рейтинги)\n",
    "X = df['Review']\n",
    "# Приводим рейтинги к диапазону [0, 4]\n",
    "y = df['Rating'] - 1  \n",
    "\n",
    "# Разделение на обучающую, валидационную и тестовую выборки (60/20/20)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, Validation size: {len(X_val)}, Test size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбор модели токенизации\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "class HotelReviewDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        tokens = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return tokens['input_ids'].squeeze(0), label\n",
    "\n",
    "# Создание датасетов\n",
    "train_dataset = HotelReviewDataset(X_train, y_train, tokenizer)\n",
    "val_dataset = HotelReviewDataset(X_val, y_val, tokenizer)\n",
    "test_dataset = HotelReviewDataset(X_test, y_test, tokenizer)\n",
    "\n",
    "# Collate-функция для паддинга\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    texts = pad_sequence(texts, batch_first=True)\n",
    "    labels = torch.tensor(labels)\n",
    "    return texts, labels\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(pl.LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes, lr=1e-4):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv = nn.Conv1d(embedding_dim, 128, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.linear = nn.Linear(128, num_classes)\n",
    "        self.lr = lr\n",
    "\n",
    "        # Метрики\n",
    "        self.train_accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "        self.train_f1 = F1Score(task=\"multiclass\", num_classes=num_classes, average=\"weighted\")\n",
    "        self.val_f1 = F1Score(task=\"multiclass\", num_classes=num_classes, average=\"weighted\")\n",
    "        self.test_f1 = F1Score(task=\"multiclass\", num_classes=num_classes, average=\"weighted\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)               # Вход: (batch_size, seq_len)\n",
    "        x = x.permute(0, 2, 1)              # Для Conv1d: (batch_size, embedding_dim, seq_len)\n",
    "        x = self.conv(x)                    # Свертка\n",
    "        x = self.relu(x)                    # Активация\n",
    "        x = self.pool(x).squeeze(-1)        # Глобальный пулинг\n",
    "        x = self.linear(x)                  # Линейный слой\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        texts, labels = batch\n",
    "        preds = self(texts)\n",
    "        loss = nn.CrossEntropyLoss()(preds, labels)\n",
    "\n",
    "        # Логируем метрики и лосс\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_accuracy\", self.train_accuracy(preds, labels), on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_f1\", self.train_f1(preds, labels), on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        texts, labels = batch\n",
    "        preds = self(texts)\n",
    "        loss = nn.CrossEntropyLoss()(preds, labels)\n",
    "\n",
    "        # Логируем метрики и лосс\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_accuracy\", self.val_accuracy(preds, labels), on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_f1\", self.val_f1(preds, labels), on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        texts, labels = batch\n",
    "        preds = self(texts)\n",
    "        loss = nn.CrossEntropyLoss()(preds, labels)\n",
    "\n",
    "        # Логируем метрики и лосс\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_accuracy\", self.test_accuracy(preds, labels), on_epoch=True)\n",
    "        self.log(\"test_f1\", self.test_f1(preds, labels), on_epoch=True)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-5)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True\n",
    "        )\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/anastasia/docs/ITMO/DL_Course/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "   | Name           | Type               | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0  | embedding      | Embedding          | 7.8 M  | train\n",
      "1  | conv           | Conv1d             | 98.4 K | train\n",
      "2  | relu           | ReLU               | 0      | train\n",
      "3  | pool           | AdaptiveMaxPool1d  | 0      | train\n",
      "4  | linear         | Linear             | 645    | train\n",
      "5  | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "6  | val_accuracy   | MulticlassAccuracy | 0      | train\n",
      "7  | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "8  | train_f1       | MulticlassF1Score  | 0      | train\n",
      "9  | val_f1         | MulticlassF1Score  | 0      | train\n",
      "10 | test_f1        | MulticlassF1Score  | 0      | train\n",
      "---------------------------------------------------------------\n",
      "7.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 M     Total params\n",
      "31.651    Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8be5806b8204b6ca5a86faac294aee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasia/docs/ITMO/DL_Course/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n",
      "/Users/anastasia/docs/ITMO/DL_Course/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20d8245ee5a4f168bb2f5710de0f7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70cb470d89546fb9f353b5e933f7a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b7fd57460b491794de3b5bf8b345d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dcde64511f1461da8f963aea939f222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17812b35f35e43598f0523ebb56b8115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dabd72ffef843e58b90787662e9e0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c47988ee2e946ffa075ddbca4bf1ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c056a327194c40f8949586e75cf2a303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f533cf35f66d449283bd3ef590528210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625ae00b7f824b2685663b3ab2e4e823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a805225735b64b09ac2b5a4eb5eb5dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9387e9f6cd0d4bbbb00286b0f670fe74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68df801b7f547f49739c45d3ddedb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bb7adcd12b4cd780e767db812f358d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313727d349ee44eca17d0f84024f51c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4566a498010b46cc99e82fe37dc610a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d1fce610c64d5da52f7d9920f2d180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620fee59e66e4312a0c03294100ae5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94c5162e45f4278bc214f1aef19362f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112a50d49aec43738a119967b5572b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c88ff113dec4f5292724a3a6b6bfa99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55166d8209c24d15a8dae5da22867f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aeca3ddec0a4af29badbc265aa9db11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d559807ae2e64035a4d7d91ddd2d1ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f496876ad42f491db754af3b58de9c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65bf39268298469c9747258af6ad0060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    }
   ],
   "source": [
    "# Гиперпараметры\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embedding_dim = 256\n",
    "num_classes = 5\n",
    "\n",
    "# Модель\n",
    "model = ConvNet(vocab_size, embedding_dim, num_classes)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=25,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    default_root_dir=\"../logs/extra_3/lightning_logs_cnn\",\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Обучение\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasia/docs/ITMO/DL_Course/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea862269e103413582044fe02780463a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.6225908994674683\n",
      "         test_f1            0.6095143556594849\n",
      "        test_loss           0.8991456627845764\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.8991456627845764,\n",
       "  'test_accuracy': 0.6225908994674683,\n",
       "  'test_f1': 0.6095143556594849}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тестирование\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"http://localhost:6013/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x31d744a90>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Запуск TensorBoard сервера\n",
    "from tensorboard import program\n",
    "from IPython.display import IFrame\n",
    "\n",
    "# Создаём объект TensorBoard\n",
    "tb = program.TensorBoard()\n",
    "tb.configure(argv=[None, \"--logdir\", \"../logs/extra_3/lightning_logs_cnn\"])\n",
    "# Запускаем TensorBoard сервер\n",
    "url = tb.launch()  \n",
    "\n",
    "# Отображение TensorBoard в IFrame\n",
    "IFrame(src=url, width=\"100%\", height=\"800px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNet(pl.LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, lr=1e-4):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(hidden_dim * 2, num_classes)  # *2 из-за bidirectional LSTM\n",
    "        self.lr = lr\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Метрики\n",
    "        self.train_accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "        self.train_f1 = F1Score(task=\"multiclass\", num_classes=num_classes, average=\"weighted\")\n",
    "        self.val_f1 = F1Score(task=\"multiclass\", num_classes=num_classes, average=\"weighted\")\n",
    "        self.test_f1 = F1Score(task=\"multiclass\", num_classes=num_classes, average=\"weighted\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)               # Вход: (batch_size, seq_len)\n",
    "        lstm_out, _ = self.lstm(x)          # Выход LSTM: (batch_size, seq_len, hidden_dim*2)\n",
    "        x = lstm_out[:, -1, :]              # Берём только последний hidden state\n",
    "        x = self.dropout(x)                 # Применяем Dropout к последнему hidden state\n",
    "        x = self.linear(x)                  # Линейный слой для классификации\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        texts, labels = batch\n",
    "        preds = self(texts)\n",
    "        loss = nn.CrossEntropyLoss()(preds, labels)\n",
    "\n",
    "        # Логируем метрики и лосс\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_accuracy\", self.train_accuracy(preds, labels), on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_f1\", self.train_f1(preds, labels), on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        texts, labels = batch\n",
    "        preds = self(texts)\n",
    "        loss = nn.CrossEntropyLoss()(preds, labels)\n",
    "\n",
    "        # Логируем метрики и лосс\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_accuracy\", self.val_accuracy(preds, labels), on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_f1\", self.val_f1(preds, labels), on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        texts, labels = batch\n",
    "        preds = self(texts)\n",
    "        loss = nn.CrossEntropyLoss()(preds, labels)\n",
    "\n",
    "        # Логируем метрики и лосс\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_accuracy\", self.test_accuracy(preds, labels), on_epoch=True)\n",
    "        self.log(\"test_f1\", self.test_f1(preds, labels), on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-5)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2, verbose=True)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/anastasia/docs/ITMO/DL_Course/.venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | embedding      | Embedding          | 7.8 M  | train\n",
      "1 | lstm           | LSTM               | 1.1 M  | train\n",
      "2 | linear         | Linear             | 2.6 K  | train\n",
      "3 | dropout        | Dropout            | 0      | train\n",
      "4 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "5 | val_accuracy   | MulticlassAccuracy | 0      | train\n",
      "6 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "7 | train_f1       | MulticlassF1Score  | 0      | train\n",
      "8 | val_f1         | MulticlassF1Score  | 0      | train\n",
      "9 | test_f1        | MulticlassF1Score  | 0      | train\n",
      "--------------------------------------------------------------\n",
      "8.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.9 M     Total params\n",
      "35.475    Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d300f214554849ef912afc68bc21896a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasia/docs/ITMO/DL_Course/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n",
      "/Users/anastasia/docs/ITMO/DL_Course/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac91561041445b788241ec0c9d31448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d719bb4cd4f4e40b7aa49cb30ec1170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8d1c8d6c084bb49f56f524bf5ede91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3488a7a4ae9c41d390ee74bb539e8fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9334f08009624d3c94282636c4de58c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d11ea3a3ba048cbb7bdcc686f753a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4866c0e170df4800986176eeb65ccb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575bd4319c674ad5854bb7bd70803092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b40b7c25cf7466f93dd3e8c1c41bd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7465a5a347c549ba9cf08482caed5eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49dc9adc63884be196c084879cde23e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3facd3e67c6b42cf9c343096a42d4b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113675bba68640579f828835eeb90a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03cacc5fc284ad384278d843c5aa2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Гиперпараметры\n",
    "embedding_dim = 256\n",
    "hidden_dim = 256\n",
    "num_classes = 5\n",
    "\n",
    "# Создание модели\n",
    "lstm_model = LSTMNet(vocab_size, embedding_dim, hidden_dim, num_classes)\n",
    "\n",
    "# Callback для ранней остановки\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "# Тренер\n",
    "trainer_lstm = pl.Trainer(\n",
    "    max_epochs=25,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    callbacks=[early_stopping],\n",
    "    default_root_dir=\"../logs/extra_3/lightning_logs_lstm\" \n",
    ")\n",
    "\n",
    "# Обучение\n",
    "trainer_lstm.fit(lstm_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasia/docs/ITMO/DL_Course/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=10` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72399bf1cebd4d43b0b9296b8122d768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.4681629538536072\n",
      "         test_f1              0.3846455514431\n",
      "        test_loss           1.2264670133590698\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.2264670133590698,\n",
       "  'test_accuracy': 0.4681629538536072,\n",
       "  'test_f1': 0.3846455514431}]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тестирование\n",
    "trainer_lstm.test(lstm_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование\n",
    "trainer_lstm.test(lstm_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение метрик CNN и RNN\n",
    "Результат у CNN получился получше в различных комбинациях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"http://localhost:6020/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x3a2e35900>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаём объект TensorBoard\n",
    "tb = program.TensorBoard()\n",
    "tb.configure(argv=[None, \"--logdir\", \"../logs/extra_3\"]) \n",
    "url = tb.launch()\n",
    "\n",
    "# Отображение TensorBoard в IFrame\n",
    "IFrame(src=url, width=\"100%\", height=\"800px\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
